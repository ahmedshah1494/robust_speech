# ################################
# Model: whisper
# Augmentation: SpecAugment
# Authors: Sung-Lin Yeh 2021
# ################################

root: !PLACEHOLDER
model_name: !ref mms-1b-fl102
hf_model_name: !ref facebook/<model_name>
output_folder: !ref <root>/trainings/<model_name>
wer_file: !ref <output_folder>/wer.txt
save_folder: !ref <output_folder>
train_log: !ref <output_folder>/train_log.txt

pretrained_path: !ref <output_folder>

attack_class: null

sample_rate: 16000
n_fft: 400
n_mels: 80
number_of_epochs: 1
# Model parameters

# Decoding parameters
blank_index: 0
# bos_index: 0
# eos_index: 0

#
# Functions and classes
#
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
   limit: !ref <number_of_epochs>

augmentation: !new:speechbrain.lobes.augment.TimeDomainSpecAugment
   sample_rate: !ref <sample_rate>
   speeds: [95, 100, 105]


asr_model: !apply:transformers.AutoModelForCTC.from_pretrained
   - !ref <hf_model_name>

# need some kind of model for the checkpoint
placeholder_model: !new:speechbrain.nnet.linear.Linear
   input_size: 8
   n_neurons: 8

modules:
   model: !ref <asr_model>
   placeholder_model: !ref <placeholder_model>

model: !new:torch.nn.ModuleList
   - [!ref <placeholder_model>]

tokenizer: !apply:transformers.AutoTokenizer.from_pretrained
   - !ref <hf_model_name>

processor: !apply:transformers.AutoProcessor.from_pretrained
   - !ref <hf_model_name>

compute_features: null

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
   save_file: !ref <train_log>

error_rate_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats

cer_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats
   split_tokens: True
ser_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats
   merge_tokens: True
fp16: false
language: en

voting_module: null