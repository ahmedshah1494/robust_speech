# ################################
# Model: whisper
# Augmentation: SpecAugment
# Authors: Sung-Lin Yeh 2021
# ################################

root: !PLACEHOLDER
model_name: !ref deepspeech
output_folder: !ref <root>/trainings/<model_name>
wer_file: !ref <output_folder>/wer.txt
save_folder: !ref <output_folder>
train_log: !ref <output_folder>/train_log.txt

pretrained_path: !ref <output_folder>

attack_class: null

sample_rate: 16000
n_fft: 400
n_mels: 80
number_of_epochs: 1
# Model parameters

# Decoding parameters
blank_index: 0
bos_index: -1
eos_index: -2

#
# Functions and classes
#
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
   limit: !ref <number_of_epochs>

augmentation: !new:speechbrain.lobes.augment.TimeDomainSpecAugment
   sample_rate: !ref <sample_rate>
   speeds: [95, 100, 105]


asr_model: !apply:robust_speech.models.modules.deepspeech.get_deepspeech_model

# need some kind of model for the checkpoint
placeholder_model: !new:speechbrain.nnet.linear.Linear
   input_size: 8
   n_neurons: 8

modules:
   model: !ref <asr_model>
   placeholder_model: !ref <placeholder_model>

model: !new:torch.nn.ModuleList
   - [!ref <placeholder_model>]

decoder: !new:deepspeech_pytorch.decoder.GreedyDecoder
   - !ref <asr_model.labels>

ctc_cost: !name:speechbrain.nnet.losses.ctc_loss
   blank_index: !ref <blank_index>

compute_features: !new:robust_speech.models.modules.deepspeech.DeepSpeechFeatureExtractor
   spec_cfg: !ref <asr_model.spect_cfg>
   normalize: True

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
   save_file: !ref <train_log>

error_rate_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats

cer_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats
   split_tokens: True
ser_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats
   merge_tokens: True
fp16: false
language: en

voting_module: null